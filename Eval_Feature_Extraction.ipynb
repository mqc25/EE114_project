{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def reshape_array(arr):\n",
    "    return arr.reshape(arr.shape[0], arr.shape[1], 1)\n",
    "\n",
    "def load_data_in(folder_name, prefix):\n",
    "    current_dir = Path('./')\n",
    "    data_dir = current_dir / folder_name\n",
    "    train_data = data_dir / '{}_train_reverb.npy'.format(prefix)\n",
    "    train_label = current_dir / 'y_train.npy'\n",
    "    test_data = data_dir / '{}_test_reverb.npy'.format(prefix)\n",
    "    test_label = current_dir / 'y_test.npy'\n",
    "    \n",
    "    with open(train_data, 'rb') as f:\n",
    "        X_train_data = np.load(f)\n",
    "        X_train_data = X_train_data.reshape(X_train_data.shape[0], X_train_data.shape[1], X_train_data.shape[2], 1)\n",
    "    with open(test_data, 'rb') as f:\n",
    "        X_test_data = np.load(test_data)\n",
    "        X_test_data = X_test_data.reshape(X_test_data.shape[0], X_test_data.shape[1], X_test_data.shape[2], 1)\n",
    "\n",
    "    with open(train_label, 'rb') as f:\n",
    "        y_train = np.load(f)\n",
    "        \n",
    "    with open(test_label, 'rb') as f:\n",
    "        y_test = np.load(f)\n",
    "        \n",
    "    return X_train_data, y_train, X_test_data, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "\n",
    "def generate_cnn_model(X_im):\n",
    "\n",
    "    n_features = X_im.shape[1]\n",
    "    time_steps = X_im.shape[2]\n",
    "    print(n_features, time_steps)\n",
    "\n",
    "    model_cnn = tf.keras.models.Sequential()\n",
    "    model_cnn.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(n_features, time_steps, 1))) # convolve with 32 kernels of size 3 x 3\n",
    "    model_cnn.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) # convolve with 32 kernels of size 3 x 3\n",
    "    model_cnn.add(tf.keras.layers.MaxPooling2D((2, 2))) #Dowmsample by 2 in each direction- take max element of every 2\n",
    "    model_cnn.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) # convolve with 64 kernels of size 3 x 3\n",
    "    model_cnn.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model_cnn.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model_cnn.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) # convolve with 128 kernels of size 3 x 3\n",
    "    model_cnn.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model_cnn.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model_cnn.add(tf.keras.layers.Flatten()) # Flatten output into a vector\n",
    "    model_cnn.add(tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform')) # Fully connected layer with 128 nodes\n",
    "    model_cnn.add(tf.keras.layers.Dense(10, activation='softmax')) #output layer, size must equal the number of classes\n",
    "\n",
    "    Adam=tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.9, amsgrad=False)\n",
    "\n",
    "    model_cnn.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam,\n",
    "                  metrics=['accuracy'])\n",
    "    model_cnn.summary() #print out breakdown of model parameters\n",
    "    \n",
    "    return model_cnn\n",
    "\n",
    "def evaluate_approach(folder_name, prefix):\n",
    "    X_train, y_train, X_test, y_test = load_data_in(folder_name, prefix)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "\n",
    "    model = generate_cnn_model(X_train)\n",
    "    \n",
    "    hist = model.fit(x=X_train, y=y_train, epochs=500, batch_size=200)\n",
    "    model.evaluate(X_test, y_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test, batch_size=200)\n",
    "    y_pred = (y_pred > 0.5) \n",
    "    \n",
    "    return model, classification_report(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, report = evaluate_approach('FE_data', 'MFCC')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, report = evaluate_approach('FE_data', 'LPC')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, report = evaluate_approach('FE_data', 'STFT')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, report = evaluate_approach('FE_data', 'GFCC')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, report = evaluate_approach('FE_data', 'PLP')\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
