{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "with open('X_train_original.npy', 'rb') as f:\n",
    "    X_train_org = np.load(f)\n",
    "\n",
    "with open('X_train_reverb_random.npy', 'rb') as f:\n",
    "    X_train_reverb = np.load(f)\n",
    "    \n",
    "with open('X_test_reverb_random.npy', 'rb') as f:\n",
    "    X_test_reverb = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    data_min = np.min(data)\n",
    "    data_max = np.max(data)\n",
    "    data_norm = (data - data_min)/(data_max - data_min)\n",
    "    return data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org_norm = normalize_data(X_train_org)\n",
    "X_train_reverb_norm = normalize_data(X_train_reverb)\n",
    "X_test_reverb_norm = normalize_data(X_test_reverb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0, 1., 1/16000)\n",
    "\n",
    "plt.plot(x, X_train_org_norm[0])\n",
    "plt.show()\n",
    "\n",
    "print(X_train_reverb_norm.shape, X_train_org_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Auto encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "\n",
    "fs = 16000\n",
    "size = 8\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=2e-126):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true_f)) + K.sum(K.square(y_pred_f)) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "model_e2e = tf.keras.models.Sequential()\n",
    "model_e2e.add(tf.keras.Input(shape=(fs,1))) #Make sure that the input size is the size of the signal\n",
    "# model_e2e.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True, )) #adjust input to unit variance and zero mean\n",
    "#First Conv1D layer\n",
    "model_e2e.add(tf.keras.layers.Conv1D(8, size, padding='same', activation='relu', strides=1)) #Convolve with 8 1D kernels of length size\n",
    "model_e2e.add(tf.keras.layers.MaxPooling1D(2)) #Downsample - take the max out of every three elements\n",
    "model_e2e.add(tf.keras.layers.Dropout(0.1)) \n",
    "model_e2e.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True, )) #adjust input to unit variance and zero mean\n",
    "#Second Conv1D layer\n",
    "model_e2e.add(tf.keras.layers.Conv1D(16, size, padding='same', activation='relu', strides=1)) #Convolve with 16 1D kernels of length 11\n",
    "model_e2e.add(tf.keras.layers.Conv1D(16, size, padding='same', activation='relu', strides=1)) #Convolve with 16 1D kernels of length 11\n",
    "model_e2e.add(tf.keras.layers.MaxPooling1D(2))\n",
    "model_e2e.add(tf.keras.layers.Dropout(0.2))\n",
    "model_e2e.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True, )) #adjust input to unit variance and zero mean\n",
    "#Third Conv1D layer\n",
    "model_e2e.add(tf.keras.layers.Conv1D(32, size, padding='same', activation='relu', strides=1))\n",
    "model_e2e.add(tf.keras.layers.Conv1D(32, size, padding='same', activation='relu', strides=1))\n",
    "model_e2e.add(tf.keras.layers.MaxPooling1D(2))\n",
    "model_e2e.add(tf.keras.layers.Dropout(0.2))\n",
    "model_e2e.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True, )) #adjust input to unit variance and zero mean\n",
    "\n",
    "model_e2e.add(tf.keras.layers.Conv1D(64, size, padding='same', activation='relu', strides=1))\n",
    "model_e2e.add(tf.keras.layers.Conv1D(64, size, padding='same', activation='relu', strides=1))\n",
    "\n",
    "model_e2e.add(tf.keras.layers.UpSampling1D(2))\n",
    "model_e2e.add(tf.keras.layers.Conv1D(32, size, padding='same', activation='relu', strides=1))\n",
    "model_e2e.add(tf.keras.layers.Conv1D(32, size, padding='same', activation='relu', strides=1))\n",
    "model_e2e.add(tf.keras.layers.Dropout(0.2))\n",
    "model_e2e.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True, )) #adjust input to unit variance and zero mean\n",
    "\n",
    "model_e2e.add(tf.keras.layers.UpSampling1D(2))\n",
    "model_e2e.add(tf.keras.layers.Conv1D(16, size, padding='same', activation='relu', strides=1))\n",
    "model_e2e.add(tf.keras.layers.Conv1D(16, size, padding='same', activation='relu', strides=1))\n",
    "model_e2e.add(tf.keras.layers.Dropout(0.2))\n",
    "model_e2e.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True, )) #adjust input to unit variance and zero mean\n",
    "\n",
    "model_e2e.add(tf.keras.layers.UpSampling1D(2))\n",
    "model_e2e.add(tf.keras.layers.Conv1D(8, size, padding='same', activation='relu', strides=1))\n",
    "model_e2e.add(tf.keras.layers.Conv1D(8, size, padding='same', activation='relu', strides=1))\n",
    "model_e2e.add(tf.keras.layers.Dropout(0.1))\n",
    "model_e2e.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True, )) #adjust input to unit variance and zero mean\n",
    "\n",
    "model_e2e.add(tf.keras.layers.Conv1D(1, 1, padding='same', strides=1))\n",
    "model_e2e.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True, )) #adjust input to unit variance and zero mean\n",
    "\n",
    "model_e2e.summary() #show breakdown of parameters\n",
    "\n",
    "model_e2e.compile(loss=dice_coef_loss, optimizer='nadam', metrics=['mse']) #decide loss function and metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the first 100 sample for evaluation\n",
    "hist = model_e2e.fit(\n",
    "    x=X_train_reverb_norm[100:], \n",
    "    y=X_train_org_norm[100:],\n",
    "    epochs=20, \n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_org_data = np.reshape( X_train_org_norm[25], (1, 16000,1))\n",
    "test_reverb_data = np.reshape( X_train_reverb_norm[25], (1, 16000,1))\n",
    "y_predict = model_e2e.predict(test_reverb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do filter on 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def denormalize_data(data, desired_min=-0.5, desired_max=0.5):\n",
    "    flat_data = data.flatten()\n",
    "    data_min = np.min(flat_data)\n",
    "    data_max = np.max(flat_data)\n",
    "    data_range = data_max - data_min\n",
    "    desired_range = desired_max - desired_min\n",
    "    \n",
    "    x = []\n",
    "    for i in range(len(flat_data)):\n",
    "        entry = (flat_data[i] - data_min) / data_range * desired_range + desired_min\n",
    "        x.append(entry)\n",
    "        \n",
    "    x = np.asarray(x)\n",
    "    print(np.min(x), np.max(x))\n",
    "    return x\n",
    "    \n",
    "y = denormalize_data(y_predict)\n",
    "\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(y.flatten())), ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "librosa.display.specshow(D, y_axis='log')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('AutoEncoder')\n",
    "plt.savefig('img/auto_encoder_fix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "\n",
    "y_int16 = denormalize_data(y, desired_min=-16384, desired_max=16383)\n",
    "\n",
    "wav.write('./audio/autoencoder_fix.wav', 16000, y_int16.astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do filter on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in tnrange(len(X_train_reverb_norm)):\n",
    "    denoised_signal = model_e2e.predict(X_train_reverb_norm[i])\n",
    "    train_data.append(denoised_signal)\n",
    "    \n",
    "train_data = np.asarray(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path('./E2E_data')\n",
    "np.save(save_dir / \"AE_train_reverb.npy\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in tnrange(len(X_test_reverb_norm)):\n",
    "    denoised_signal = model_e2e.predict(X_test_reverb_norm[i])\n",
    "    test_data.append(denoised_signal)\n",
    "    \n",
    "test_data = np.asarray(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path('./E2E_data')\n",
    "np.save(save_dir / \"AE_test_reverb.npy\", test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
