{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def reshape_array(arr):\n",
    "    return arr.reshape(arr.shape[0], arr.shape[1], 1)\n",
    "\n",
    "def load_data_in(folder_name, prefix):\n",
    "    current_dir = Path('./')\n",
    "    data_dir = current_dir / folder_name\n",
    "    train_data = data_dir / '{}_train_reverb.npy'.format(prefix)\n",
    "    train_label = current_dir / 'y_train.npy'\n",
    "    test_data = data_dir / '{}_test_reverb.npy'.format(prefix)\n",
    "    test_label = current_dir / 'y_test.npy'\n",
    "    \n",
    "    with open(train_data, 'rb') as f:\n",
    "        X_train_data = np.load(f)\n",
    "        X_train_data = reshape_array(X_train_data)\n",
    "        \n",
    "    with open(test_data, 'rb') as f:\n",
    "        X_test_data = np.load(test_data)\n",
    "        X_test_data = reshape_array(X_test_data)\n",
    "        \n",
    "    with open(train_label, 'rb') as f:\n",
    "        y_train = np.load(f)\n",
    "        \n",
    "    with open(test_label, 'rb') as f:\n",
    "        y_test = np.load(f)\n",
    "        \n",
    "    return X_train_data, y_train, X_test_data, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2E Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "\n",
    "def generate_e2e_model():\n",
    "    fs = 16000\n",
    "    model_e2e = tf.keras.models.Sequential()\n",
    "    model_e2e.add(tf.keras.Input(shape=(fs,1))) #Make sure that the input size is the size of the signal\n",
    "    model_e2e.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True, )) #adjust input to unit variance and zero mean\n",
    "    #First Conv1D layer\n",
    "    model_e2e.add(tf.keras.layers.Conv1D(8,13, padding='valid', activation='relu', strides=1)) #Convolve with 8 1D kernels of length 13\n",
    "    model_e2e.add(tf.keras.layers.MaxPooling1D(3)) #Downsample - take the max out of every three elements\n",
    "    model_e2e.add(tf.keras.layers.Dropout(0.3)) #drop nodes with probability 0.3\n",
    "    #Second Conv1D layer\n",
    "    model_e2e.add(tf.keras.layers.Conv1D(16, 11, padding='valid', activation='relu', strides=1)) #Convolve with 16 1D kernels of length 11\n",
    "    model_e2e.add(tf.keras.layers.MaxPooling1D(3))\n",
    "    model_e2e.add(tf.keras.layers.Dropout(0.3))\n",
    "    #Third Conv1D layer\n",
    "    model_e2e.add(tf.keras.layers.Conv1D(32, 9, padding='valid', activation='relu', strides=1))\n",
    "    model_e2e.add(tf.keras.layers.MaxPooling1D(3))\n",
    "    model_e2e.add(tf.keras.layers.Dropout(0.3))\n",
    "    model_e2e.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True))\n",
    "    model_e2e.add(tf.keras.layers.Bidirectional(tf.python.keras.layers.CuDNNGRU(128, return_sequences=True), merge_mode='sum')) #Recurrent layer, uses time series data\n",
    "    model_e2e.add(tf.keras.layers.Bidirectional(tf.python.keras.layers.CuDNNGRU(128, return_sequences=True), merge_mode='sum'))\n",
    "    model_e2e.add(tf.keras.layers.Bidirectional(tf.python.keras.layers.CuDNNGRU(128, return_sequences=False), merge_mode='sum')) #set return sequences to False for last recurrent layer\n",
    "    model_e2e.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True))\n",
    "    #Flatten layer\n",
    "    model_e2e.add(tf.keras.layers.Flatten()) # Turn 2D result of convolution to a single vector\n",
    "    #Dense Layer 1\n",
    "    model_e2e.add(tf.keras.layers.Dense(256, activation='relu')) #Fully connected layer\n",
    "    model_e2e.add(tf.keras.layers. Dense(10, activation=\"softmax\")) #output layer, need size = num_classes\n",
    "    model_e2e.summary() #show breakdown of parameters\n",
    "\n",
    "    model_e2e.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy']) #decide loss function and metrics\n",
    "    \n",
    "    return model_e2e\n",
    "\n",
    "def evaluate_approach(folder_name, prefix):\n",
    "    X_train, y_train, X_test, y_test = load_data_in(folder_name, prefix)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "\n",
    "    model = generate_e2e_model()\n",
    "    \n",
    "    hist = model.fit(x=X_train, y=y_train, epochs=50, batch_size=32)\n",
    "    model.evaluate(X_test, y_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test, batch_size=32)\n",
    "    y_pred = (y_pred > 0.5) \n",
    "    \n",
    "    return model, classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, report = evaluate_approach('E2E_data', 'X')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, report = evaluate_approach('E2E_data', 'Vnet')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, report = evaluate_approach('E2E_data', 'AE')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, report = evaluate_approach('E2E_data', 'WPE')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, report = evaluate_approach('E2E_data', 'ConvTasnet')\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
