{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "with open('X_train_original.npy', 'rb') as f:\n",
    "    X_train_org = np.load(f)\n",
    "\n",
    "    \n",
    "with open('X_train_reverb_random.npy', 'rb') as f:\n",
    "    X_train_reverb = np.load(f)\n",
    "    \n",
    "with open('X_test_reverb_random.npy', 'rb') as f:\n",
    "    X_test_reverb = np.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    data_min = np.min(data)\n",
    "    data_max = np.max(data)\n",
    "    data_norm = (data - data_min)/(data_max - data_min)\n",
    "    return data_norm\n",
    "\n",
    "X_train_org_norm = normalize_data(X_train_org)\n",
    "X_train_reverb_norm = normalize_data(X_train_reverb)\n",
    "X_test_reverb_norm = normalize_data(X_test_reverb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X_train_org_norm[0])\n",
    "plt.show()\n",
    "\n",
    "print(X_train_org_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, initializers, regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "def prepare_vnet_encoder(config, inputs, trainable=True):\n",
    "    prev_output = inputs\n",
    "    regularizer = regularizers.l2(0.001)\n",
    "    save_layers = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(config)):\n",
    "        layer_prev_output = prev_output\n",
    "        for j in range(config[i][1]):\n",
    "            c = layers.Conv1D(config[i][0], 100, kernel_initializer='he_normal',\n",
    "                              trainable=trainable, kernel_regularizer=regularizer,\n",
    "                              padding='same', name='dw_c{}_{}'.format(i, j))(prev_output)\n",
    "            \n",
    "            # skip connection\n",
    "            if j == config[i][1] - 1 and i != 0:\n",
    "                c = layers.Add()([c, layer_prev_output])\n",
    "              \n",
    "            c = layers.Activation('relu')(c)\n",
    "            c = tf.keras.layers.BatchNormalization()(c)\n",
    "                \n",
    "            prev_output = c\n",
    "        \n",
    "        # down convolution\n",
    "        if i != len(config) -1:\n",
    "            save_layers.append(c)\n",
    "            c = layers.Conv1D(config[i][0] * 2, 2, strides=2, kernel_initializer='he_normal',\n",
    "                              trainable=trainable, kernel_regularizer=regularizer, activation='elu',\n",
    "                              padding='same', name='p_cd{}_{}'.format(i, j))(c)\n",
    "            c = tf.keras.layers.BatchNormalization()(c)\n",
    "            prev_output = c\n",
    "    \n",
    "    return prev_output, save_layers\n",
    "        \n",
    "def prepare_vnet_decoder(config, inputs, skip_layers, trainable=True):\n",
    "    prev_output = inputs\n",
    "    regularizer = regularizers.l2(0.001)\n",
    "    \n",
    "    for i in range(len(config)):\n",
    "        # up deconvolution\n",
    "        u = layers.Conv1DTranspose(config[i][0], 2, strides=2, activation='elu',\n",
    "                                   kernel_initializer='he_normal', trainable=trainable,\n",
    "                                   padding='same', name='up_u{}_1'.format(i))(prev_output)\n",
    "        u = tf.keras.layers.BatchNormalization()(u)\n",
    "        layer_prev_output = u\n",
    "        prev_output = u        \n",
    "        for j in range(config[i][1]):\n",
    "            # long skip connection\n",
    "            if j == 0:\n",
    "                c = layers.concatenate([prev_output, skip_layers[-(i+1)]])\n",
    "            else:\n",
    "                c = prev_output\n",
    "\n",
    "            c = layers.Conv1D(config[i][0], 100, kernel_initializer='he_normal', trainable=trainable,\n",
    "                            kernel_regularizer=regularizer, padding='same', name='up_cd{}_{}'.format(i, j))(c)\n",
    "            \n",
    "            # short skip connection\n",
    "            if j == config[i][1] -1:\n",
    "                c = layers.Add()([c, layer_prev_output])\n",
    "            \n",
    "            c = layers.Activation('elu')(c)\n",
    "            c = tf.keras.layers.BatchNormalization()(c)\n",
    "                \n",
    "        prev_output = c\n",
    "        \n",
    "    return prev_output\n",
    "        \n",
    "def prepare_vnet(config, weight_path=None):\n",
    "    input_shape = config['input_size']\n",
    "    output_size = config['output_size']\n",
    "    loss_function = config['loss_function']\n",
    "    \n",
    "\n",
    "    #Build the model\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "    \n",
    "    encoder_config = [[16, 1], [32, 2], [64, 3], [128, 3], [256, 3]]\n",
    "    encoder, skip_layers = prepare_vnet_encoder(encoder_config, inputs)\n",
    "    \n",
    "    decoder_config = [[128, 3], [64, 3], [32, 2], [16, 1]]\n",
    "    decoder = prepare_vnet_decoder(decoder_config, encoder, skip_layers)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv1D(1, 1)(decoder)\n",
    "    full_model = keras.Model(inputs=inputs,\n",
    "                             outputs=outputs)\n",
    "\n",
    "#     if weight_path is not None:\n",
    "#         full_model.load_weights(weight_path)\n",
    "\n",
    "#     full_model.compile(optimizer='adam',\n",
    "#                        loss=loss_function,\n",
    "#                        metrics=['mae'])\n",
    "    return full_model\n",
    "\n",
    "size = 16000\n",
    "test_config={\n",
    "    \"input_size\": (size, 1),\n",
    "    \"output_size\": (size, 1),\n",
    "    \"loss_function\": 'mse'\n",
    "}\n",
    "\n",
    "\n",
    "model = None\n",
    "model = prepare_vnet(test_config)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=2e-126):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true_f)) + K.sum(K.square(y_pred_f)) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, epoch, batch_size):\n",
    "    size = 16000\n",
    "    test_config={\n",
    "        \"input_size\": (size, 1),\n",
    "        \"output_size\": (size, 1),\n",
    "        \"loss_function\": 'mse'\n",
    "    }\n",
    "\n",
    "    model = None\n",
    "    model = prepare_vnet(test_config)\n",
    "    model.compile('Adam', dice_coef_loss, ['mae'])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epoch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(X_train_reverb_norm[100:], X_train_org_norm[100:], 20, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "from scipy.signal import freqs\n",
    "from scipy import signal\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do filter on one data + remove artifact with bandpass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_org_data = np.reshape( X_train_org_norm[25], (1, 16000,1))\n",
    "test_reverb_data = np.reshape( X_train_reverb_norm[25], (1, 16000,1))\n",
    "y_predict = model.predict(test_reverb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def denormalize_data(data, desired_min=-0.5, desired_max=0.5):\n",
    "    flat_data = data.flatten()\n",
    "    data_min = np.min(flat_data)\n",
    "    data_max = np.max(flat_data)\n",
    "    data_range = data_max - data_min\n",
    "    desired_range = desired_max - desired_min\n",
    "    \n",
    "    x = []\n",
    "    for i in range(len(flat_data)):\n",
    "        entry = (flat_data[i] - data_min) / data_range * desired_range + desired_min\n",
    "        x.append(entry)\n",
    "        \n",
    "    x = np.asarray(x)\n",
    "    print(np.min(x), np.max(x))\n",
    "    return x\n",
    "    \n",
    "y = denormalize_data(y_predict)\n",
    "y = butter_bandpass_filter(y, 20, 4000, 16000)\n",
    "\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(y.flatten())), ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "librosa.display.specshow(D, y_axis='log')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Vnet')\n",
    "plt.savefig('img/vnet_fix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "\n",
    "y_int16 = denormalize_data(y, desired_min=-16384, desired_max=16383)\n",
    "\n",
    "wav.write('./audio/vnet_fix.wav', 16000, y_int16.astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do filter on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tnrange\n",
    "\n",
    "train_data = []\n",
    "for i in tnrange(len(X_train_reverb_norm)):\n",
    "    denoised_signal = model.predict(X_train_reverb_norm[i])\n",
    "    y = butter_bandpass_filter(denoised_signal, 20, 4000, 16000)\n",
    "    train_data.append(y)\n",
    "    \n",
    "train_data = np.asarray(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path('./E2E_data')\n",
    "np.save(save_dir / \"Vnet_train_reverb.npy\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in tnrange(len(X_test_reverb_norm)):\n",
    "    denoised_signal = model.predict(X_test_reverb_norm[i])\n",
    "    y = butter_bandpass_filter(denoised_signal, 20, 4000, 16000)\n",
    "    test_data.append(y)\n",
    "    \n",
    "test_data = np.asarray(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path('./E2E_data')\n",
    "np.save(save_dir / \"Vnet_train_reverb.npy\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
